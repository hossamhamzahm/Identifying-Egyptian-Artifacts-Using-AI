{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#imports\nimport time\nimport torch\nimport torch.nn as nn #neural network module\nimport torch.optim as optim #optimizers (e.g. Gradient Descent Stochastic Gradient Descent (SGD))\nimport torch.nn.functional as F # contains activation functions\nfrom torch.utils.data import DataLoader # to load data set\nimport torchvision.datasets as datasets # to download dataset form mnisc\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-26T21:32:29.941821Z","iopub.execute_input":"2023-08-26T21:32:29.942183Z","iopub.status.idle":"2023-08-26T21:32:29.949045Z","shell.execute_reply.started":"2023-08-26T21:32:29.942152Z","shell.execute_reply":"2023-08-26T21:32:29.947562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def timer(f, txt=\"time\"):\n    def wrapper(*args):\n        tic = time.time()\n        val = f(*args)\n        tac = time.time() - tic\n\n        print(txt, tac, \"ms\")\n        return val\n    return wrapper","metadata":{"execution":{"iopub.status.busy":"2023-08-26T21:32:29.954879Z","iopub.execute_input":"2023-08-26T21:32:29.955861Z","iopub.status.idle":"2023-08-26T21:32:29.964714Z","shell.execute_reply.started":"2023-08-26T21:32:29.955822Z","shell.execute_reply":"2023-08-26T21:32:29.963586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying Transforms to the Data\nimage_transforms = { \n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n        transforms.RandomRotation(degrees=15),\n        transforms.RandomHorizontalFlip(),\n        transforms.CenterCrop(size=224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n    'valid': transforms.Compose([\n        transforms.Resize(size=256),\n        transforms.CenterCrop(size=224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize(size=256),\n        transforms.CenterCrop(size=224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ])\n}","metadata":{"execution":{"iopub.status.busy":"2023-08-26T21:32:29.975893Z","iopub.execute_input":"2023-08-26T21:32:29.976164Z","iopub.status.idle":"2023-08-26T21:32:29.985121Z","shell.execute_reply.started":"2023-08-26T21:32:29.976141Z","shell.execute_reply":"2023-08-26T21:32:29.984073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set device \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n# Set train and valid directory paths\ntrain_directory = \"/kaggle/input/monuments-v0/monuments/monuments/train\"\ntest_directory = \"/kaggle/input/monuments-v0/monuments/monuments/test\"\ntest2_directory = \"/kaggle/input/monuments-v0/test2/test2\"\nvalid_directory = \"/kaggle/input/monuments-v0/monuments/monuments/valid\"\n\n# Batch size\nbs = 32\n\n# Number of classes\nnum_classes = 5\n\n# how many times the entire dataset is fed to the network\nepochs = 4\n\n\n# Load Data from folders\ndata = {\n    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid']),\n    'test': datasets.ImageFolder(root=test_directory, transform=image_transforms['test'])\n}\n\n# Size of Data, to be used for calculating Average Loss and Accuracy\ntest_data2 = DataLoader(datasets.ImageFolder(root=test2_directory, transform=image_transforms['test']), batch_size=bs, shuffle=True)\ntest_data_size2 = len(datasets.ImageFolder(root=test2_directory, transform=image_transforms['test']))\nclass_names = datasets.ImageFolder(root=test2_directory, transform=image_transforms['test']).classes\n\n\ntrain_data_size = len(data['train'])\nvalid_data_size = len(data['valid'])\ntest_data_size = len(data['test'])\n\n\n# Create iterators for the Data loaded using DataLoader module\ndata['train'], data['test'], data['valid'] = torch.utils.data.random_split(data['train'], [0.7, 0.15, 0.15], generator=torch.Generator().manual_seed(42))\ntrain_data_size = len(data['train'])\nvalid_data_size = len(data['test'])\ntest_data_size = len(data['valid'])\n\ntrain_data = DataLoader(data['train'], batch_size=bs, shuffle=True)\nvalid_data = DataLoader(data['valid'], batch_size=bs, shuffle=True)\ntest_data = DataLoader(data['test'], batch_size=bs, shuffle=True)\n\n# Print the train, validation and test set data sizes\ntrain_data_size, valid_data_size, test_data_size\n","metadata":{"execution":{"iopub.status.busy":"2023-08-26T21:32:30.013752Z","iopub.execute_input":"2023-08-26T21:32:30.014102Z","iopub.status.idle":"2023-08-26T21:32:37.661307Z","shell.execute_reply.started":"2023-08-26T21:32:30.014073Z","shell.execute_reply":"2023-08-26T21:32:37.660197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load pretrained ResNet50 Model\nresnet50 = models.resnet50(pretrained=True) # True to allow learning transfer\n\n\n# Freeze model parameters\nfor param in resnet50.parameters():\n    param.requires_grad = False\n\n\n# Change the final layer of ResNet50 Model for Transfer Learning\nfc_inputs = resnet50.fc.in_features\nresnet50.fc = nn.Sequential(\n    nn.Linear(fc_inputs, 256),\n    nn.ReLU(),\n    nn.Dropout(0.4),\n    nn.Linear(256, num_classes), \n    nn.LogSoftmax(dim=1) # For using NLLLoss()\n)\n\n\n# Convert model to be used on GPU\nresnet50 = resnet50.to(device)\n\n\n# Define Optimizer and Loss Function\nloss_func = nn.NLLLoss()\noptimizer = optim.Adam(resnet50.parameters())\nhistory = []\n\n\n\n\ndef train():\n    for epoch in range(epochs):\n            epoch_start = time.time()\n            print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n            # Set to training mode\n            resnet50.train()\n            # Loss and Accuracy within the epoch\n            train_loss = 0.0\n            train_acc = 0.0\n            valid_loss = 0.0\n            valid_acc = 0.0\n            for i, (inputs, labels) in enumerate(train_data):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                # Clean existing gradients\n                optimizer.zero_grad()\n                # Forward pass - compute outputs on input data using the model\n                outputs = resnet50(inputs)\n                # Compute loss\n                loss = loss_func(outputs, labels)\n                # Backpropagate the gradients\n                loss.backward()\n                # Update the parameters\n                optimizer.step()\n                # Compute the total loss for the batch and add it to train_loss\n                train_loss += loss.item() * inputs.size(0)\n                # Compute the accuracy\n                ret, predictions = torch.max(outputs.data, 1)\n                correct_counts = predictions.eq(labels.data.view_as(predictions))\n                # Convert correct_counts to float and then compute the mean\n                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n                # Compute total accuracy in the whole batch and add to train_acc\n                train_acc += acc.item() * inputs.size(0)\n                print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n    # Validation - No gradient tracking needed\n            with torch.no_grad():\n                # Set to evaluation mode\n                resnet50.eval()\n                # Validation loop\n                for j, (inputs, labels) in enumerate(valid_data):\n                    inputs = inputs.to(device)\n                    labels = labels.to(device)\n                    # Forward pass - compute outputs on input data using the model\n                    outputs = resnet50(inputs)\n                    # Compute loss\n                    loss = loss_func(outputs, labels)\n                    # Compute the total loss for the batch and add it to valid_loss\n                    valid_loss += loss.item() * inputs.size(0)\n                    # Calculate validation accuracy\n                    ret, predictions = torch.max(outputs.data, 1)\n                    correct_counts = predictions.eq(labels.data.view_as(predictions))\n                    # Convert correct_counts to float and then compute the mean\n                    acc = torch.mean(correct_counts.type(torch.FloatTensor))\n                    # Compute total accuracy in the whole batch and add to valid_acc\n                    valid_acc += acc.item() * inputs.size(0)\n                    print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n            # Find average training loss and training accuracy\n            avg_train_loss = train_loss/train_data_size \n            avg_train_acc = train_acc/float(train_data_size)\n            # Find average training loss and training accuracy\n            avg_valid_loss = valid_loss/valid_data_size \n            avg_valid_acc = valid_acc/float(valid_data_size)\n            history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n            epoch_end = time.time()\n            print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, nttValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T21:32:37.663366Z","iopub.execute_input":"2023-08-26T21:32:37.663690Z","iopub.status.idle":"2023-08-26T21:32:42.450437Z","shell.execute_reply.started":"2023-08-26T21:32:37.663663Z","shell.execute_reply":"2023-08-26T21:32:42.449276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def chech_accuracy(loader, model):\n    num_correct=0\n    num_samples=0\n    model.eval()\n\n\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device=device)\n            y = y.to(device=device)\n\n            scores = model(x)\n            _, predictions = scores.max(1)\n            \n            print(y)\n            print(predictions)\n\n            \n            num_correct += (y == predictions).sum()\n            num_samples += predictions.size(0)\n\n        print(f'Got {num_correct}/{num_samples} with accuracy {float(num_correct)/float(num_samples)}')\n    \n    model.train()\n\n\n\ndef predict(model, test_image_name):\n    transform = image_transforms['test']\n    test_image = Image.open(test_image_name)\n    plt.imshow(test_image)\n    test_image_tensor = transform(test_image)\n    if torch.cuda.is_available():\n        test_image_tensor = test_image_tensor.view(1, 3, 224, 224).cuda()\n    else:\n        test_image_tensor = test_image_tensor.view(1, 3, 224, 224)\n    with torch.no_grad():\n        model.eval()\n        # Model outputs log probabilities\n        out = model(test_image_tensor)\n        ps = torch.exp(out)\n        topk, topclass = ps.topk(1, dim=1)\n        print(\"Output class :  \", idx_to_class[topclass.cpu().numpy()[0][0]])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-26T21:32:42.451927Z","iopub.execute_input":"2023-08-26T21:32:42.452405Z","iopub.status.idle":"2023-08-26T21:32:42.464829Z","shell.execute_reply.started":"2023-08-26T21:32:42.452368Z","shell.execute_reply":"2023-08-26T21:32:42.463512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params_path = \"/kaggle/working/params_epoch4_augmented_data\"\n\n\n# train()\n# torch.save(resnet50.state_dict(), params_path)\nresnet50.load_state_dict(torch.load(params_path))\n\n# chech_accuracy(test_data, resnet50)\nprint(class_names)\nchech_accuracy(test_data2, resnet50)\n# chech_accuracy(valid_data, resnet50)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-26T21:39:52.544883Z","iopub.execute_input":"2023-08-26T21:39:52.545251Z","iopub.status.idle":"2023-08-26T21:39:53.169426Z","shell.execute_reply.started":"2023-08-26T21:39:52.545221Z","shell.execute_reply":"2023-08-26T21:39:53.168469Z"},"trusted":true},"execution_count":null,"outputs":[]}]}